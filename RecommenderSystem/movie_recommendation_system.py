# -*- coding: utf-8 -*-
"""Movie Recommendation System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c_KlwtyT2pHR3StBHTKUAYIsHojUBk9U

# Movie Recommendation System

## Data Diri
Nama Lengkap: Kresna Devara

## Import Library
"""

!pip install scikit-surprise

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import nltk
from collections import Counter
from math import sqrt
from sklearn.feature_extraction.text import CountVectorizer
from nltk.tokenize import word_tokenize
from sklearn.metrics.pairwise import cosine_distances
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from surprise import Reader, Dataset, SVD
from surprise.model_selection import cross_validate
from surprise.model_selection import train_test_split

# %matplotlib inline

nltk.download('punkt')

"""## Import Data"""

# download data
!gdown 1Y3YDqlOmM9QywgHBF3hm0-GFytDep4w_

!unzip "MoviesDataset.zip" -d MoviesDataset

df_movies = pd.read_csv('MoviesDataset/movies.csv')
df_movies.head(5)

df_ratings = pd.read_csv('MoviesDataset/ratings.csv')
df_ratings.head()

"""## Exploratory Data Analysis

### Deskripsi dan Check Data

**Penjelasan Data**
***
- MovieId: Unique id dari film
- title: Judul dari film
- Genre: Tipe genre dari film
- UserId: Unique id dari user
- rating: Penilaian film dari user
- timestamp: waktu melakukan submit survey

**Data Check**
***
"""

# movies dataframe
df_movies.info()

df_movies.nunique()

# ratings dataframe
df_ratings.info()

df_ratings.nunique()

print("Total Null movies dataframe: " + str(df_movies.isnull().sum().sum()))
print("Total NA movies dataframe: " + str(df_movies.isna().sum().sum()))

print("Total Null ratings dataframe: " + str(df_ratings.isnull().sum().sum()))
print("Total NA ratings dataframe: " + str(df_ratings.isna().sum().sum()))

"""Tidak ada data yang kosong"""

df_ratings.describe()

"""### Univariate Analysis

#### Kolom Genre

Pada kolom genre, jenis genre bukanlah hanya 1 saja, tertapi mutli genre, sehingga untuk mengetahui total jenis genre perlu dilakukan processing terlebih dahulu.
"""

categories = list()
genres = [p.split("|") for p in df_movies.genres.values] 
for c in genres:
  categories += c

pd_genre = pd.DataFrame(Counter(categories).items(), columns=['Category', 'Total'])
pd_genre

pd_genre.plot.bar(x='Category', y='Total', title='Jumlah Genre pada Film', figsize=(15,5), rot=45)

"""__Analisa Univariate analyis Genre__
***
1. Film dengan Genre dan Comedy memiliki jumlah dua terbanyak.
2. Terdapat film yang genrenya tidak dijelaskanya **(no genres listed)**

Selanjutnya film dengan genre yang tidak dijelaskan akan dihapus (didrop)

#### Analisa Kolom Rating
"""

df_ratings['rating'].value_counts().plot.bar(xlabel='Rating', ylabel='Total', title='Jumlah Rating keseluruhan', figsize=(15,5))

"""__Analisa Univariate analyis kolom Rating__
***
1. Diketahui bahwa user paling banyak memilih rating 4.0.
2. Rating 0.5 memiliki jumlah paling sedikit.

## Data Preparation

### Membuang data duplikasi

Diketahui dari proses sebelumnya bahwa terdapat film dengan judul yang sama (duplikasi) sehingga film-film tersebut akan dijadikan 1. Sedangkan tidak ada data duplikasi pada ratings
"""

df_movies[df_movies.title.duplicated()]

df_ratings[df_ratings.duplicated()]

df_movies = df_movies[~df_movies.title.duplicated()]
df_movies.head()

df_movies.nunique()

"""### Membuang data yang tidak diperlukan

Diketahui dari proses sebelumnya bahwa, tidak ada data yang kosong (Null/NA). Namun terdapat film yang memiliki Genre **(not listed)** sehingga film dengan genre tersebut akan didrop, yaitu pada bagian genre yang tidak terdaftar pada dataframe movies dan juga timestamp pada dataframe rating (karena tidak diggunakan)
"""

df_movies = df_movies[df_movies['genres'] != '(no genres listed)']
df_movies.head(100)

df_movies.info()

df_ratings.drop('timestamp', axis=1, inplace=True)
df_ratings.head()

"""### Merge Dataset

Untuk melakukan collaborative filtering, data frame ratings akan digabungkan dengan dataframe movies
"""

df_combine = pd.merge(df_ratings, df_movies, on='movieId', how='left')
# df_combine.drop(['title', 'genres'], axis=1, inplace=True)
df_combine

"""### Tokenisasi dan Bank Token Content Based Filtering

Pada Content Based Filtering kita hanya akan menggunakan Dataframe movies
"""

# make bank of token
bow = CountVectorizer(stop_words="english", tokenizer=word_tokenize)
bank = bow.fit_transform(df_movies.genres)

"""### Train Test Split Collaborative Filtering"""

df_combine_new = df_combine.copy()
df_combine_new.drop(['title', 'genres'], axis=1, inplace=True)

data = Dataset.load_from_df(df_combine_new, Reader(rating_scale=(0.5, 5)))

trainset, testset = train_test_split(data, test_size=0.3, random_state=42)

"""## Modeling

### Content Based Filtering

#### Step 1: Encode
"""

idx = 0
content = df_movies.loc[idx, 'genres']
content

code = bow.transform([content])
code

"""#### Step 2: Document Search"""

dist = cosine_distances(code, bank)
dist

rec_idx = dist.argsort()[0, 1:11]
rec_idx

"""#### Step 3: Rekomendasi"""

df_movies.loc[rec_idx]

"""#### Membuat Class"""

class ContentRecommender:
  """
  df: dataframe 
  content_col: nama kolom yang akan dianalisa
  """
  def __init__(self, dataframe, content_col):
    self.df = dataframe
    self.content_col = content_col
    self.encoder = None
    self.bank = None
      
  def fit(self):
    self.encoder = CountVectorizer(stop_words="english", tokenizer=word_tokenize)
    self.bank = self.encoder.fit_transform(self.df[self.content_col])

  def recommend(self, idx, topk=10):
    """
    idx: Nomor index input
    topk: Nomor rekomendasi yang diinginkan
    """
    content = self.df.loc[idx, self.content_col]
    code = self.encoder.transform([content])
    dist = cosine_distances(code, self.bank)
    rec_idx = dist.argsort()[0,1:(topk+1)]
    return self.df.loc[rec_idx]

contentrec = ContentRecommender(df_movies, 'genres')
contentrec.fit()

contentrec.recommend(1, topk=10)

"""film dengan index 1 adalah Jumanji (1995)	dengan Adventure|Children|Fantasy, dari 10 rekomendasi yang diberikan. terdapat 8 film dengan genre yang hampir sama. Hanya 2 film saja yang memiliki genre yang berbeda.

### Collaborative Filtering

Collaborative Filtering kali ini akan menggunakan model SVD
"""

model = SVD(random_state=42)
model.fit(trainset)

"""#### Melakukan prediksi Film yang Belum diTonton"""

user_id = 1
watched = df_combine[df_combine.userId == user_id].movieId

all_moviesId = df_combine.movieId.unique()

not_watched = [movieId for movieId in all_moviesId if movieId not in watched]

score = [model.predict(user_id, movie).est for movie in not_watched]
score[:10]

"""#### Membuat class"""

class CollaborativeRecommender:
  def __init__(self, data):
    self.df_full = data.copy()
    self.df_process = data.copy()
    self.df_process.drop(['title', 'genres'], axis=1, inplace=True)

    self.all_movies =  self.df_process.movieId.unique()
    self.model = None

  def fit(self):
    data = Dataset.load_from_df(self.df_process, Reader())
    trainset = data.build_full_trainset()
    
    self.model = SVD(random_state=42)
    self.model.fit(trainset)
           
  def recommend(self, user_id, topk=10):
    watched = self.df_process[self.df_process.userId == user_id].movieId
    not_watched = [movie for movie in self.all_movies if movie not in watched]
    score = [self.model.predict(user_id, movie).est for movie in not_watched]
    title = [self.df_full[self.df_full['movieId'] == n].title.unique()[0] for n in not_watched]
    genres = [self.df_full[self.df_full['movieId'] == n].genres.unique()[0] for n in not_watched]
    
    result = pd.DataFrame({"movieId": not_watched, "title": title, "genres": genres, "pred_score":score})
    result.sort_values("pred_score", ascending=False, inplace=True)
    return result.head(topk)

collrecs = CollaborativeRecommender(df_combine)

collrecs.fit()

collrecs.recommend(0, topk=10)

"""## Metrik Evaluasi

### Content Based Filtering

Evaluasi yang digunakan pada Content Based Filtering adalah Precission dimana: \
`P = Jumlah rekomendasi yang relevan/Jumlah rekomendasi`

kita akan melakukan rekomendasi sebanyak 20 dan akan melihat jumlah yang relevan
"""

contentrec.recommend(1, topk=20)

"""Pada contoh di diatas dari 20 film yang direkomendasikan ada 14 film yang relevan, dan 6 yang tidak sehingga Precisionnya <br>
`P = 14/20 = 0.7 = 70%`

### Collaborative Filtering

Pada Collaborative Filtering, Rating Prediki akan dibandingan dengan Rating aslinya dengan menggunakan Root Mean Square Error dari model pada sesi sebelumnya
"""

test_result = model.test(testset)
df_test = pd.DataFrame(test_result)
df_test.drop('details', axis=1, inplace=True)
df_test.columns = ['userId', 'movieId', 'Rating_actual', 'Rating_predictions']

df_test.head()

mae = mean_absolute_error(df_test.Rating_actual, df_test.Rating_predictions)
mse = mean_squared_error(df_test.Rating_actual, df_test.Rating_predictions)
rms = sqrt(mse)
print(f"MAE: {mae}\nMSE: {mse}\nRMSE :{rms}")

"""## Kesimpulan

Meskipun tidak dapat dibandingan secara langsung (Head to Head) antara Content based filtering dan juga Collaborative Filtering. Namun hasil evaluasi metrik pada keduanya cukup bagus dimana Contant-Based Memiliki Presisi sebesar 70% dan RMSE 0.88 pada Collaborative Filtering
"""